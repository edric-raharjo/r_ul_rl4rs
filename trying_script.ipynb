{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fdc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Reload Modules\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4d2e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to weights\\dqn_untrained.pt\n",
      "\n",
      "=== A (untrained) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Kuliah\\Kuliah\\Kuliah\\PRODI\\Semester 7\\ProSkripCode\\rul_venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: {'num_steps': 360.0, 'hit@1': 0.6138888888888889, 'ndcg@1': 0.6820987654320988, 'ndcg@1_num_valid': 324.0, 'hit@3': 0.7805555555555556, 'ndcg@3': 0.7044235983012636, 'ndcg@3_num_valid': 324.0, 'hit@5': 0.8472222222222222, 'ndcg@5': 0.7547887637291426, 'ndcg@5_num_valid': 324.0, 'hit@9': 0.9, 'ndcg@9': 0.8593136822735822, 'ndcg@9_num_valid': 324.0}\n",
      "Forget: {'num_steps': 360.0, 'hit@1': 0.5027777777777778, 'ndcg@1': 0.5156695156695157, 'ndcg@1_num_valid': 351.0, 'hit@3': 0.7777777777777778, 'ndcg@3': 0.5572555411575187, 'ndcg@3_num_valid': 351.0, 'hit@5': 0.8833333333333333, 'ndcg@5': 0.6307790381276709, 'ndcg@5_num_valid': 351.0, 'hit@9': 0.975, 'ndcg@9': 0.7840613558081819, 'ndcg@9_num_valid': 351.0}\n",
      "\n",
      "=== Epoch 1/15 ===\n",
      "[step 0] loss=1.003390 avg_loss=1.003390\n",
      "\n",
      "=== Epoch 2/15 ===\n",
      "\n",
      "=== Epoch 3/15 ===\n",
      "\n",
      "=== Epoch 4/15 ===\n",
      "\n",
      "=== Epoch 5/15 ===\n",
      "\n",
      "=== Epoch 6/15 ===\n",
      "\n",
      "=== Epoch 7/15 ===\n",
      "\n",
      "=== Epoch 8/15 ===\n",
      "\n",
      "=== Epoch 9/15 ===\n",
      "\n",
      "=== Epoch 10/15 ===\n",
      "\n",
      "=== Epoch 11/15 ===\n",
      "[step 50] loss=0.410866 avg_loss=0.410866\n",
      "\n",
      "=== Epoch 12/15 ===\n",
      "\n",
      "=== Epoch 13/15 ===\n",
      "\n",
      "=== Epoch 14/15 ===\n",
      "\n",
      "=== Epoch 15/15 ===\n",
      "Saved model to weights\\dqn_basic.pt\n",
      "\n",
      "=== B (trained) ===\n",
      "Test: {'num_steps': 360.0, 'hit@1': 0.6555555555555556, 'ndcg@1': 0.7283950617283951, 'ndcg@1_num_valid': 324.0, 'hit@3': 0.7777777777777778, 'ndcg@3': 0.7386285287362558, 'ndcg@3_num_valid': 324.0, 'hit@5': 0.8527777777777777, 'ndcg@5': 0.7804780183015047, 'ndcg@5_num_valid': 324.0, 'hit@9': 0.9, 'ndcg@9': 0.8732220685040509, 'ndcg@9_num_valid': 324.0}\n",
      "Forget: {'num_steps': 360.0, 'hit@1': 0.5833333333333334, 'ndcg@1': 0.5982905982905983, 'ndcg@1_num_valid': 351.0, 'hit@3': 0.8194444444444444, 'ndcg@3': 0.6207442759109019, 'ndcg@3_num_valid': 351.0, 'hit@5': 0.9055555555555556, 'ndcg@5': 0.6772622654580662, 'ndcg@5_num_valid': 351.0, 'hit@9': 0.975, 'ndcg@9': 0.8106818131232194, 'ndcg@9_num_valid': 351.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.data_loader import LogConfig, ItemConfig, load_log_table, load_item_table\n",
    "from dataset.rl4rs_dataset import RL4RSDataset9Step\n",
    "from train.train_dqn_basic import train_dqn_basic, TrainConfig\n",
    "\n",
    "from eval.evaluate import evaluate\n",
    "\n",
    "\n",
    "def split_df_log_train_forget_test(df_log, train_ratio=0.6, forget_ratio=0.2, test_ratio=0.2, seed=42):\n",
    "    assert abs(train_ratio + forget_ratio + test_ratio - 1.0) < 1e-9\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(df_log))\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n_train = int(len(df_log) * train_ratio)\n",
    "    n_forget = int(len(df_log) * forget_ratio)\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    forget_idx = idx[n_train:n_train + n_forget]\n",
    "    test_idx = idx[n_train + n_forget:]\n",
    "\n",
    "    return (\n",
    "        df_log.iloc[train_idx].reset_index(drop=True),\n",
    "        df_log.iloc[forget_idx].reset_index(drop=True),\n",
    "        df_log.iloc[test_idx].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(df_log_part, df_item):\n",
    "    return RL4RSDataset9Step(\n",
    "        df_log=df_log_part,\n",
    "        df_item=df_item,\n",
    "        slate_size=9,\n",
    "        use_tier_flags=True,\n",
    "        tier_weights=(1.0, 2.0, 4.0),\n",
    "        exclude_history_candidates=True\n",
    "    )\n",
    "\n",
    "\n",
    "def train_on(df_log_train, df_item, cfg):\n",
    "    ds = make_dataset(df_log_train, df_item)\n",
    "    loader = DataLoader(ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    sample0 = ds[0]\n",
    "    state_dim = sample0[\"state\"].numel()\n",
    "    item_dim = sample0[\"item_vec\"].numel()\n",
    "\n",
    "    q = train_dqn_basic(\n",
    "        train_loader=loader,\n",
    "        state_dim=state_dim,\n",
    "        item_dim=item_dim,\n",
    "        hidden_dim=256,\n",
    "        cfg=cfg\n",
    "    )\n",
    "    return q\n",
    "\n",
    "\n",
    "def eval_report(tag, model, test_ds, forget_ds, device, ks=(1, 3, 5, 9)):\n",
    "    print(f\"\\n=== {tag} ===\")\n",
    "    print(\"Test:\", evaluate(model, test_ds, device=device, ks=ks))\n",
    "    print(\"Forget:\", evaluate(model, forget_ds, device=device, ks=ks))\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_path = r\"E:\\Kuliah\\Kuliah\\Kuliah\\PRODI\\Semester 7\\ProSkripCode\\data\\raw\\trainset.csv\"\n",
    "    item_path = r\"E:\\Kuliah\\Kuliah\\Kuliah\\PRODI\\Semester 7\\ProSkripCode\\data\\raw\\item_info.csv\"\n",
    "\n",
    "    log_cfg = LogConfig(path=log_path, slate_size=9, max_click_history=50)\n",
    "    item_cfg = ItemConfig(path=item_path, item_vec_dim=None)\n",
    "\n",
    "    df_log = load_log_table(log_cfg).reset_index(drop=True)\n",
    "    df_item = load_item_table(item_cfg)\n",
    "\n",
    "    df_log = df_log.iloc[:200].reset_index(drop=True)\n",
    "\n",
    "    df_train, df_forget, df_test = split_df_log_train_forget_test(df_log, 0.6, 0.2, 0.2, seed=42)\n",
    "\n",
    "    test_ds = make_dataset(df_test, df_item)\n",
    "    forget_ds = make_dataset(df_forget, df_item)\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        lr=1e-3,\n",
    "        gamma=0.99,\n",
    "        batch_size=256,\n",
    "        num_epochs=15,\n",
    "        target_update=\"hard\",\n",
    "        hard_update_interval=500,\n",
    "        save_dir=\"weights\",\n",
    "        save_name=\"dqn_basic.pt\"\n",
    "    )\n",
    "\n",
    "    # A: untrained baseline (kalau train_dqn_basic tidak support 0 epoch, skip A)\n",
    "    try:\n",
    "        cfg_A = TrainConfig(\n",
    "            device=cfg.device, lr=cfg.lr, gamma=cfg.gamma, batch_size=cfg.batch_size,\n",
    "            num_epochs=0,\n",
    "            target_update=cfg.target_update, hard_update_interval=cfg.hard_update_interval,\n",
    "            save_dir=cfg.save_dir, save_name=\"dqn_untrained.pt\"\n",
    "        )\n",
    "        q_A = train_on(df_train, df_item, cfg_A)\n",
    "        eval_report(\"A (untrained)\", q_A, test_ds, forget_ds, cfg.device)\n",
    "    except Exception as e:\n",
    "        print(\"\\n(A untrained diskip) train_dqn_basic tidak support num_epochs=0:\", repr(e))\n",
    "\n",
    "    # B: trained\n",
    "    q_B = train_on(df_train, df_item, cfg)\n",
    "    eval_report(\"B (trained)\", q_B, test_ds, forget_ds, cfg.device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd61013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.data_loader import LogConfig, ItemConfig, load_log_table, load_item_table\n",
    "from dataset.rl4rs_dataset import RL4RSDataset9Step\n",
    "from train.train_dqn_basic import train_dqn_basic, TrainConfig\n",
    "from eval.evaluate import evaluate\n",
    "\n",
    "\n",
    "def split_df_log_train_forget_test(df_log, train_ratio=0.6, forget_ratio=0.2, test_ratio=0.2, seed=42):\n",
    "    assert abs(train_ratio + forget_ratio + test_ratio - 1.0) < 1e-9\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(df_log))\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n_train = int(len(df_log) * train_ratio)\n",
    "    n_forget = int(len(df_log) * forget_ratio)\n",
    "\n",
    "    train_idx = idx[:n_train]\n",
    "    forget_idx = idx[n_train:n_train + n_forget]\n",
    "    test_idx = idx[n_train + n_forget:]\n",
    "\n",
    "    return (\n",
    "        df_log.iloc[train_idx].reset_index(drop=True),\n",
    "        df_log.iloc[forget_idx].reset_index(drop=True),\n",
    "        df_log.iloc[test_idx].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(df_log_part, df_item):\n",
    "    return RL4RSDataset9Step(\n",
    "        df_log=df_log_part,\n",
    "        df_item=df_item,\n",
    "        slate_size=9,\n",
    "        use_tier_flags=True,\n",
    "        tier_weights=(1.0, 2.0, 4.0),\n",
    "        exclude_history_candidates=True\n",
    "    )\n",
    "\n",
    "\n",
    "def train_on(df_log_train, df_item, cfg, forget_loader=None):\n",
    "    ds = make_dataset(df_log_train, df_item)\n",
    "    loader = DataLoader(ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    sample0 = ds[0]\n",
    "    state_dim = sample0[\"state\"].numel()\n",
    "    item_dim = sample0[\"item_vec\"].numel()\n",
    "\n",
    "    q = train_dqn_basic(\n",
    "        train_loader=loader,\n",
    "        state_dim=state_dim,\n",
    "        item_dim=item_dim,\n",
    "        hidden_dim=256,\n",
    "        cfg=cfg,\n",
    "        forget_loader=forget_loader  # <-- NEW: untuk decremental RL\n",
    "    )\n",
    "    return q\n",
    "\n",
    "\n",
    "def eval_report(tag, model, test_ds, forget_ds, device, ks=(1, 3, 5, 9)):\n",
    "    print(f\"\\n=== {tag} ===\")\n",
    "    print(\"Test:\", evaluate(model, test_ds, device=device, ks=ks))\n",
    "    print(\"Forget:\", evaluate(model, forget_ds, device=device, ks=ks))\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_path = r\"E:\\Kuliah\\Kuliah\\Kuliah\\PRODI\\Semester 7\\ProSkripCode\\data\\raw\\trainset.csv\"\n",
    "    item_path = r\"E:\\Kuliah\\Kuliah\\Kuliah\\PRODI\\Semester 7\\ProSkripCode\\data\\raw\\item_info.csv\"\n",
    "\n",
    "    log_cfg = LogConfig(path=log_path, slate_size=9, max_click_history=50)\n",
    "    item_cfg = ItemConfig(path=item_path, item_vec_dim=None)\n",
    "\n",
    "    df_log = load_log_table(log_cfg).reset_index(drop=True)\n",
    "    df_item = load_item_table(item_cfg)\n",
    "\n",
    "    df_log = df_log.iloc[:200].reset_index(drop=True)\n",
    "\n",
    "    df_train, df_forget, df_test = split_df_log_train_forget_test(df_log, 0.6, 0.2, 0.2, seed=42)\n",
    "\n",
    "    test_ds = make_dataset(df_test, df_item)\n",
    "    forget_ds = make_dataset(df_forget, df_item)\n",
    "\n",
    "    # Loader untuk forget (dipakai saat decremental/unlearning)\n",
    "    forget_loader = DataLoader(\n",
    "        forget_ds,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        lr=1e-3,\n",
    "        gamma=0.99,\n",
    "        batch_size=256,\n",
    "        num_epochs=5,\n",
    "        target_update=\"hard\",\n",
    "        hard_update_interval=500,\n",
    "        save_dir=\"weights\",\n",
    "        save_name=\"dqn_basic.pt\"\n",
    "    )\n",
    "\n",
    "    # A: untrained baseline (optional)\n",
    "    try:\n",
    "        cfg_A = TrainConfig(\n",
    "            device=cfg.device, lr=cfg.lr, gamma=cfg.gamma, batch_size=cfg.batch_size,\n",
    "            num_epochs=0,\n",
    "            target_update=cfg.target_update, hard_update_interval=cfg.hard_update_interval,\n",
    "            save_dir=cfg.save_dir, save_name=\"dqn_untrained.pt\"\n",
    "        )\n",
    "        q_A = train_on(df_train, df_item, cfg_A)\n",
    "        eval_report(\"A (untrained)\", q_A, test_ds, forget_ds, cfg.device)\n",
    "    except Exception as e:\n",
    "        print(\"\\n(A untrained diskip) train_dqn_basic tidak support num_epochs=0:\", repr(e))\n",
    "\n",
    "    # B: trained (basic)\n",
    "    # q_B = train_on(df_train, df_item, cfg)\n",
    "    # eval_report(\"B (trained)\", q_B, test_ds, forget_ds, cfg.device)\n",
    "\n",
    "    # C: trained + decremental RL unlearning on forget\n",
    "    cfg_C = TrainConfig(\n",
    "        device=cfg.device,\n",
    "        lr=cfg.lr,\n",
    "        gamma=cfg.gamma,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_epochs=cfg.num_epochs,\n",
    "        target_update=cfg.target_update,\n",
    "        hard_update_interval=cfg.hard_update_interval,\n",
    "        save_dir=cfg.save_dir,\n",
    "        save_name=\"dqn_basic_then_dec.pt\"\n",
    "    )\n",
    "\n",
    "    # --- aktifkan decremental ---\n",
    "    cfg_C.do_decremental = True\n",
    "    cfg_C.dec_epochs = 3\n",
    "    cfg_C.dec_lr = 1e-4\n",
    "    cfg_C.dec_alpha = 0.5\n",
    "    cfg_C.dec_save_name = \"dqn_decremental.pt\"\n",
    "\n",
    "    q_C = train_on(df_train, df_item, cfg_C, forget_loader=forget_loader)\n",
    "    eval_report(\"C (basic + decremental)\", q_C, test_ds, forget_ds, cfg.device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59287da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Script executed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rul_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
